{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Simply Static Post Process \u00b6 A Python Library to prepare and deploy a static version of a WordPress Installation on Netlify (Static Hosting Service Provider). How to Use simply-static-post-process? \u00b6 Please check our detailed tutorial (video/text) on Simply Static Post Process Tutorial to understand how it works. This package has a live documentation file on documentation link . Contributions \u00b6 Contributions, suggestions, and comments are welcome. Please fork the repository and submit a pull request. About Us \u00b6 This work is a collaborative effort of seowings and serpwings . LICENSE \u00b6 Simply Static Netlify Process is released under MIT License . src\\search.js is distributed without any additional licensing restrictions. Please consult src\\search.js for more details.","title":"Home"},{"location":"#simply-static-post-process","text":"A Python Library to prepare and deploy a static version of a WordPress Installation on Netlify (Static Hosting Service Provider).","title":"Simply Static Post Process"},{"location":"#how-to-use-simply-static-post-process","text":"Please check our detailed tutorial (video/text) on Simply Static Post Process Tutorial to understand how it works. This package has a live documentation file on documentation link .","title":"How to Use simply-static-post-process?"},{"location":"#contributions","text":"Contributions, suggestions, and comments are welcome. Please fork the repository and submit a pull request.","title":"Contributions"},{"location":"#about-us","text":"This work is a collaborative effort of seowings and serpwings .","title":"About Us"},{"location":"#license","text":"Simply Static Netlify Process is released under MIT License . src\\search.js is distributed without any additional licensing restrictions. Please consult src\\search.js for more details.","title":"LICENSE"},{"location":"helper-functions/","text":"Helper Functions \u00b6 Simply Static Netlify Process https://github.com/serpwings/simply-static-post-process A Python Library to prepare and deploy static version of a WordPress Installation on Netlify (Static Hosting Service Providers). MIT License Copyright (c) 2023 SERP Wings Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. log_to_console(typ='INFO', message='') \u00b6 help to log text streams (input as message) to console. Parameters: Name Type Description Default typ str Type of log. Default to INFO but can be any arbitrary value e.g. ERROR , DEBUG and etc. 'INFO' message str , required message string to be logged into console. '' Source code in src/helpers.py def log_to_console(typ=\"INFO\", message=\"\"): \"\"\" help to log text streams (input as message) to console. Args: typ (str, optional): Type of log. Default to ``INFO`` but can be any arbitrary value e.g. ``ERROR``, ``DEBUG`` and etc. message (str, required): message string to be logged into console. \"\"\" print(f\"{typ}: {message}\") string_formatter(str) \u00b6 String formatter for html formatting output. Parameters: Name Type Description Default ua_name str , required string to be formatted. required Source code in src/helpers.py def string_formatter(str): \"\"\" String formatter for html formatting output. Args: ua_name (str, required): string to be formatted. \"\"\" return str update_links(content='', link_from='', link_to='') \u00b6 Usefull for fixing schema or other links which simply static cannot fix. Parameters: Name Type Description Default content str , required Text which you want to update links e.g. Cotent on Home Page. '' link_from str , required string values of link which you want to change. '' link_to str , required string values of links to be replaced with. '' Source code in src/helpers.py def update_links(content=\"\", link_from=\"\", link_to=\"\"): \"\"\" Usefull for fixing schema or other links which simply static cannot fix. Args: content (str, required): Text which you want to update links e.g. Cotent on Home Page. link_from (str, required): string values of link which you want to change. link_to (str, required): string values of links to be replaced with. \"\"\" if link_from and link_to and content: link_from = link_from.split(\"://\")[-1] link_to = link_to.split(\"://\")[-1] return content.replace(link_from, link_to) return content","title":"Helper Functions"},{"location":"helper-functions/#helper-functions","text":"Simply Static Netlify Process https://github.com/serpwings/simply-static-post-process A Python Library to prepare and deploy static version of a WordPress Installation on Netlify (Static Hosting Service Providers). MIT License Copyright (c) 2023 SERP Wings Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"Helper Functions"},{"location":"helper-functions/#src.helpers.log_to_console","text":"help to log text streams (input as message) to console. Parameters: Name Type Description Default typ str Type of log. Default to INFO but can be any arbitrary value e.g. ERROR , DEBUG and etc. 'INFO' message str , required message string to be logged into console. '' Source code in src/helpers.py def log_to_console(typ=\"INFO\", message=\"\"): \"\"\" help to log text streams (input as message) to console. Args: typ (str, optional): Type of log. Default to ``INFO`` but can be any arbitrary value e.g. ``ERROR``, ``DEBUG`` and etc. message (str, required): message string to be logged into console. \"\"\" print(f\"{typ}: {message}\")","title":"log_to_console()"},{"location":"helper-functions/#src.helpers.string_formatter","text":"String formatter for html formatting output. Parameters: Name Type Description Default ua_name str , required string to be formatted. required Source code in src/helpers.py def string_formatter(str): \"\"\" String formatter for html formatting output. Args: ua_name (str, required): string to be formatted. \"\"\" return str","title":"string_formatter()"},{"location":"helper-functions/#src.helpers.update_links","text":"Usefull for fixing schema or other links which simply static cannot fix. Parameters: Name Type Description Default content str , required Text which you want to update links e.g. Cotent on Home Page. '' link_from str , required string values of link which you want to change. '' link_to str , required string values of links to be replaced with. '' Source code in src/helpers.py def update_links(content=\"\", link_from=\"\", link_to=\"\"): \"\"\" Usefull for fixing schema or other links which simply static cannot fix. Args: content (str, required): Text which you want to update links e.g. Cotent on Home Page. link_from (str, required): string values of link which you want to change. link_to (str, required): string values of links to be replaced with. \"\"\" if link_from and link_to and content: link_from = link_from.split(\"://\")[-1] link_to = link_to.split(\"://\")[-1] return content.replace(link_from, link_to) return content","title":"update_links()"},{"location":"simply-static-netlify/","text":"StaticWordPressNetlify Class \u00b6 This is a class processing Simply Static WordPress Plugin and converting it to netlify static site. Attributes: Name Type Description config dic Contains all important configurations about the class. output_folder Path Contains Path for output folder location in Netlify zip_file_path Path ZIP File Path to download simply-static-zip file freom remote server. redirect_page Path Contains Path of redirect page robots_txt_page Path Contains Path of robots.txt page self._404_page Path Contains Path of 404 Page Source code in src/main.py class StaticWordPressNetlify: \"\"\" This is a class processing Simply Static WordPress Plugin and converting it to netlify static site. Attributes: config (dic): Contains all important configurations about the class. output_folder (Path): Contains Path for output folder location in Netlify zip_file_path (Path): ZIP File Path to download simply-static-zip file freom remote server. redirect_page (Path): Contains Path of redirect page robots_txt_page (Path): Contains Path of robots.txt page self._404_page (Path): Contains Path of 404 Page \"\"\" def __init__(self, config_=None): \"\"\"Initialize StaticWordPressNetlify objet with a config values. Args: config_ (dict, optional): contains diverse conditions for StaticWordPressNetlify object. \"\"\" if config_: self.config = config_ self.output_folder = Path(self.config[\"root\"], self.config[\"output_folder\"]) self.zip_file_path = Path(self.config[\"root\"], self.config[\"zip_file_name\"]) self.redirect_page = Path( self.output_folder, self.config[\"pages\"][\"redirect\"] ) self.robots_txt_page = Path( self.output_folder, self.config[\"pages\"][\"robots\"] ) self._404_page = Path( self.output_folder, self.config[\"pages\"][\"404\"], \"index.html\" ) def download_zip_file(self): \"\"\"Download zip file from remote server\"\"\" helpers.log_to_console(\"INFO\", configurations[\"zip_url\"]) headers = CaseInsensitiveDict() headers[\"Cache-Control\"] = \"no-cache, no-store, must-revalidate\" headers[\"Pragma\"] = \"no-cache\" headers[\"Expires\"] = \"0\" current_session = requests.session() response = current_session.get(configurations[\"zip_url\"], headers=headers) if response.status_code == 200: with open(self.config[\"zip_file_name\"], \"wb\") as fd: for chunk in response.iter_content(chunk_size=128): fd.write(chunk) helpers.log_to_console(\"INFO\", \"Simply Static Zip File Downloaded\") else: helpers.log_to_console(\"ERROR\", \"Simply Static Zip File Not available\") current_session.cookies.clear() def create_output_folder(self): \"\"\"Create Ouput Folder it it doesnot exist.\"\"\" if not self.output_folder.is_dir(): self.output_folder.mkdir(parents=True, exist_ok=True) helpers.log_to_console(\"INFO\", \"Output Folder Created\") else: helpers.log_to_console(\"ERROR\", \"Cannot Create Output Folder\") def create_robots_txt(self): \"\"\"Create Robots.txt File using robots-txt page. Default would be ``User-agent: *``\"\"\" robots_path = Path( self.robots_txt_page, \"index.html\", ) if robots_path.exists(): with codecs.open(robots_path, \"r\", \"utf-8\") as f: robots_txt_contents = f.read() soup = BeautifulSoup(robots_txt_contents, \"lxml\") robots_table = soup.find_all(\"table\")[0] with open(f\"{self.output_folder}/robots.txt\", \"w\") as f: for row in robots_table.tbody.find_all(\"tr\"): f.write(\"\".join([cell.text.strip(\"\\r\") for cell in row(\"td\")])) f.write(\"\\n\") shutil.rmtree(Path(self.output_folder, self.config[\"pages\"][\"robots\"])) else: with open(f\"{self.output_folder}/robots.txt\", \"w\") as f: f.write(\"User-agent: * \\n\") f.write(\"Disallow: /wp-admin/ \\n\") f.write(\"Allow: /wp-admin/admin-ajax.php \\n\") helpers.log_to_console(\"INFO\", \"Created robots.txt file\") def extract_zip_file(self): \"\"\"Extract simply static zip file to ouput folder.\"\"\" if self.output_folder.is_dir(): zf = ZipFile(self.zip_file_path, \"r\") zf.extractall(self.output_folder) zf.close() helpers.log_to_console(\"INFO\", \"Zip File Extracted\") else: helpers.log_to_console(\"ERROR\", \"Cannot extract Zip File\") def fix_404_error_page(self): \"\"\"Fix 404 page by moving it to home directory. It deletes old folder.\"\"\" try: with codecs.open(self._404_page, \"r\", \"utf-8\") as f: contents_404_page = f.read() contents_404_page = helpers.update_links( contents_404_page, self.config[\"callback_home\"], self.config[\"callback_deploy_url\"], ) with open( Path(self.output_folder, \"404.html\"), \"w\", encoding=\"utf-8\" ) as f: f.write(contents_404_page) helpers.log_to_console(\"INFO\", \"404 Page Created\") shutil.rmtree(Path(self.output_folder, self.config[\"pages\"][\"404\"])) helpers.log_to_console(\"INFO\", \"404 Folder Removed\") except: helpers.log_to_console(\"ERROR\", \"404 Page Not Created\") def fix_home_page(self): \"\"\"Fix Schemas and other links on home page which are ignored by simply static plugin.\"\"\" home_page_path = Path(self.output_folder, \"index.html\") try: with codecs.open(home_page_path, \"r\", \"utf-8\") as f: contents_home_page = f.read() contents_home_page = helpers.update_links( contents_home_page, self.config[\"callback_home\"], self.config[\"callback_deploy_url\"], ) with open(home_page_path, \"w\", encoding=\"utf-8\") as f: f.write(contents_home_page) helpers.log_to_console(\"INFO\", \"Fixed Home Page\") except: helpers.log_to_console(\"ERROR\", \"Home Page can not be fixed\") def build_search_index(self): \"\"\"Buidl search index by using title, body content and href of a given page\"\"\" helpers.log_to_console(\"INFO\", \"Start Building Search Index\") try: # Copy Search.js into search folder source_path = Path(self.config[\"root\"], \"src/search.js\") target_path = Path( self.output_folder, f\"{self.config['pages']['search']}/search.js\" ) shutil.copyfile(source_path, target_path) # Now Process all foldre with content/index.html files paths_to_pages = [ path.split(\"index.html\")[0] for path in glob.glob(f\"{self.output_folder}/**\", recursive=True) if path.endswith(\"index.html\") ] search_index_output = [] for page_path in paths_to_pages: make_title = self.config[\"search\"][\"title\"] make_url = self.config[\"search\"][\"url\"] make_text = self.config[\"search\"][\"text\"] make_images = self.config[\"search\"][\"images\"] document_path = Path(page_path, \"index.html\") if document_path.exists(): with codecs.open(document_path, \"r\", \"utf-8\") as f: contents_document_page = f.read() contents_document_page = helpers.update_links( contents_document_page, self.config[\"callback_home\"], self.config[\"callback_deploy_url\"], ) soup = BeautifulSoup(contents_document_page, \"lxml\") # append tags only if search page is specified if \"/search/\" in str(document_path): script_text = [ soup.new_tag( \"script\", src=LUNR[\"src\"], integrity=LUNR[\"integrity\"], crossorigin=LUNR[\"crossorigin\"], referrerpolicy=LUNR[\"referrerpolicy\"], ), soup.new_tag( \"script\", src=SEARCH_INDEX[\"src\"], ), ] for script in script_text: soup.find(\"head\").append(str(script)) # TODO: In future add support for minification check updated_content = soup.prettify( formatter=HTMLFormatter(helpers.string_formatter) ) with open(document_path, \"w\", encoding=\"utf-8\") as f: f.write(updated_content) title = soup.find(\"title\") title = title.string if title else None url = soup.find(\"meta\", {\"property\": \"og:url\"}) url = url[\"content\"] if url else None canonical = soup.find(\"link\", {\"rel\": \"canonical\"}) if canonical: url = canonical[\"href\"] all_strings = soup.body.find_all([\"h1\", \"h2\", \"h3\", \"p\"]) output = [ strings for bd in all_strings for strings in bd.strings ] text = \" \".join(output) if url and document_path.parts[-2] not in [ self.config[\"pages\"][page] for page in self.config[\"pages\"] ]: out = { \"title\": title if make_title else \"\", \"content\": text if make_text else \"\", \"href\": url if make_url else \"\", } search_index_output.append(out) helpers.log_to_console(\"INFO\", url) search_index_json_file_path = Path( self.output_folder, self.config[\"pages\"][\"search\"], \"lunr.json\", ) with open(search_index_json_file_path, \"w\") as fl: json.dump(search_index_output, fl, indent=4) helpers.log_to_console( \"INFO\", \"Prepare Search Index for title, Url and Text\" ) except: helpers.log_to_console(\"ERROR\", \"Search Index not Generated\") def clean_directory_check(self): \"\"\" \"\"\" helpers.log_to_console( \"INFO\", \"Started Removing Bad URLs/Directories for forceful deploy.\" ) files = [f for f in glob.glob(f\"{self.output_folder}/**/*\", recursive=True)] for f in files: if \"#\" in f or \"?\" in f: if os.path.exists(f) and os.path.isdir(f): print(f\"removing {f} for forceful deploy.\") shutil.rmtree(f) helpers.log_to_console(\"INFO\", \"Removed Bad URLs/Directories from deployement.\") def create_redirect_toml_file(self): \"\"\"Create netlify.toml file with redirects information freom redirect page.\"\"\" helpers.log_to_console( \"INFO\", \"Source Redirect Page \" + self.config[\"pages\"][\"redirect\"] ) redirect_path = Path( self.redirect_page, \"index.html\", ) rules = [ [ \"[[redirects]]\\n\", 'from = \"/*\"\\n', f'to = \"/{self.config[\"pages\"][\"search\"]}\"\\n', \"status = 301\\n\", 'query = {s = \":s\"}\\n', \"force = true\\n\", \"\\n\", ] ] if redirect_path.exists(): with codecs.open(redirect_path, \"r\", \"utf-8\") as f: contents = f.read() soup = BeautifulSoup(contents, \"lxml\") redirect_table = soup.find_all(\"table\")[0] table_data = [ [cell.text.strip(\"\\r\") for cell in row(\"td\")] for row in redirect_table.tbody.find_all(\"tr\") ] helpers.log_to_console( \"WARNING\", f\"Redirect Rules found - {len(table_data)}\" ) if len(table_data) > 1: for data in table_data[1:]: if data[3].strip() == \"1\": rules.append( [ f\"[[redirects]]\\n\", f'{table_data[0][0].lower().strip()} = \"{data[0].strip()}\"\\n', f'{table_data[0][1].lower().strip()} = \"{data[1].strip()}\"\\n', f\"{table_data[0][2].lower().strip()} = {data[2].strip()}\\n\", \"\\n\", ] ) shutil.rmtree(self.redirect_page) else: helpers.log_to_console(\"WARNING\", \"No Redirect File found\") netlify_toml_file = Path(self.output_folder, \"netlify.toml\") with open(netlify_toml_file, \"w\", encoding=\"utf-8\") as f: f.writelines([\"\".join(rule) for rule in rules]) helpers.log_to_console(\"INFO\", \"Netlify toml File Created Successfully\") __init__(config_=None) \u00b6 Initialize StaticWordPressNetlify objet with a config values. Parameters: Name Type Description Default config_ dict contains diverse conditions for StaticWordPressNetlify object. None Source code in src/main.py def __init__(self, config_=None): \"\"\"Initialize StaticWordPressNetlify objet with a config values. Args: config_ (dict, optional): contains diverse conditions for StaticWordPressNetlify object. \"\"\" if config_: self.config = config_ self.output_folder = Path(self.config[\"root\"], self.config[\"output_folder\"]) self.zip_file_path = Path(self.config[\"root\"], self.config[\"zip_file_name\"]) self.redirect_page = Path( self.output_folder, self.config[\"pages\"][\"redirect\"] ) self.robots_txt_page = Path( self.output_folder, self.config[\"pages\"][\"robots\"] ) self._404_page = Path( self.output_folder, self.config[\"pages\"][\"404\"], \"index.html\" ) build_search_index() \u00b6 Buidl search index by using title, body content and href of a given page Source code in src/main.py def build_search_index(self): \"\"\"Buidl search index by using title, body content and href of a given page\"\"\" helpers.log_to_console(\"INFO\", \"Start Building Search Index\") try: # Copy Search.js into search folder source_path = Path(self.config[\"root\"], \"src/search.js\") target_path = Path( self.output_folder, f\"{self.config['pages']['search']}/search.js\" ) shutil.copyfile(source_path, target_path) # Now Process all foldre with content/index.html files paths_to_pages = [ path.split(\"index.html\")[0] for path in glob.glob(f\"{self.output_folder}/**\", recursive=True) if path.endswith(\"index.html\") ] search_index_output = [] for page_path in paths_to_pages: make_title = self.config[\"search\"][\"title\"] make_url = self.config[\"search\"][\"url\"] make_text = self.config[\"search\"][\"text\"] make_images = self.config[\"search\"][\"images\"] document_path = Path(page_path, \"index.html\") if document_path.exists(): with codecs.open(document_path, \"r\", \"utf-8\") as f: contents_document_page = f.read() contents_document_page = helpers.update_links( contents_document_page, self.config[\"callback_home\"], self.config[\"callback_deploy_url\"], ) soup = BeautifulSoup(contents_document_page, \"lxml\") # append tags only if search page is specified if \"/search/\" in str(document_path): script_text = [ soup.new_tag( \"script\", src=LUNR[\"src\"], integrity=LUNR[\"integrity\"], crossorigin=LUNR[\"crossorigin\"], referrerpolicy=LUNR[\"referrerpolicy\"], ), soup.new_tag( \"script\", src=SEARCH_INDEX[\"src\"], ), ] for script in script_text: soup.find(\"head\").append(str(script)) # TODO: In future add support for minification check updated_content = soup.prettify( formatter=HTMLFormatter(helpers.string_formatter) ) with open(document_path, \"w\", encoding=\"utf-8\") as f: f.write(updated_content) title = soup.find(\"title\") title = title.string if title else None url = soup.find(\"meta\", {\"property\": \"og:url\"}) url = url[\"content\"] if url else None canonical = soup.find(\"link\", {\"rel\": \"canonical\"}) if canonical: url = canonical[\"href\"] all_strings = soup.body.find_all([\"h1\", \"h2\", \"h3\", \"p\"]) output = [ strings for bd in all_strings for strings in bd.strings ] text = \" \".join(output) if url and document_path.parts[-2] not in [ self.config[\"pages\"][page] for page in self.config[\"pages\"] ]: out = { \"title\": title if make_title else \"\", \"content\": text if make_text else \"\", \"href\": url if make_url else \"\", } search_index_output.append(out) helpers.log_to_console(\"INFO\", url) search_index_json_file_path = Path( self.output_folder, self.config[\"pages\"][\"search\"], \"lunr.json\", ) with open(search_index_json_file_path, \"w\") as fl: json.dump(search_index_output, fl, indent=4) helpers.log_to_console( \"INFO\", \"Prepare Search Index for title, Url and Text\" ) except: helpers.log_to_console(\"ERROR\", \"Search Index not Generated\") create_output_folder() \u00b6 Create Ouput Folder it it doesnot exist. Source code in src/main.py def create_output_folder(self): \"\"\"Create Ouput Folder it it doesnot exist.\"\"\" if not self.output_folder.is_dir(): self.output_folder.mkdir(parents=True, exist_ok=True) helpers.log_to_console(\"INFO\", \"Output Folder Created\") else: helpers.log_to_console(\"ERROR\", \"Cannot Create Output Folder\") create_redirect_toml_file() \u00b6 Create netlify.toml file with redirects information freom redirect page. Source code in src/main.py def create_redirect_toml_file(self): \"\"\"Create netlify.toml file with redirects information freom redirect page.\"\"\" helpers.log_to_console( \"INFO\", \"Source Redirect Page \" + self.config[\"pages\"][\"redirect\"] ) redirect_path = Path( self.redirect_page, \"index.html\", ) rules = [ [ \"[[redirects]]\\n\", 'from = \"/*\"\\n', f'to = \"/{self.config[\"pages\"][\"search\"]}\"\\n', \"status = 301\\n\", 'query = {s = \":s\"}\\n', \"force = true\\n\", \"\\n\", ] ] if redirect_path.exists(): with codecs.open(redirect_path, \"r\", \"utf-8\") as f: contents = f.read() soup = BeautifulSoup(contents, \"lxml\") redirect_table = soup.find_all(\"table\")[0] table_data = [ [cell.text.strip(\"\\r\") for cell in row(\"td\")] for row in redirect_table.tbody.find_all(\"tr\") ] helpers.log_to_console( \"WARNING\", f\"Redirect Rules found - {len(table_data)}\" ) if len(table_data) > 1: for data in table_data[1:]: if data[3].strip() == \"1\": rules.append( [ f\"[[redirects]]\\n\", f'{table_data[0][0].lower().strip()} = \"{data[0].strip()}\"\\n', f'{table_data[0][1].lower().strip()} = \"{data[1].strip()}\"\\n', f\"{table_data[0][2].lower().strip()} = {data[2].strip()}\\n\", \"\\n\", ] ) shutil.rmtree(self.redirect_page) else: helpers.log_to_console(\"WARNING\", \"No Redirect File found\") netlify_toml_file = Path(self.output_folder, \"netlify.toml\") with open(netlify_toml_file, \"w\", encoding=\"utf-8\") as f: f.writelines([\"\".join(rule) for rule in rules]) helpers.log_to_console(\"INFO\", \"Netlify toml File Created Successfully\") create_robots_txt() \u00b6 Create Robots.txt File using robots-txt page. Default would be User-agent: * Source code in src/main.py def create_robots_txt(self): \"\"\"Create Robots.txt File using robots-txt page. Default would be ``User-agent: *``\"\"\" robots_path = Path( self.robots_txt_page, \"index.html\", ) if robots_path.exists(): with codecs.open(robots_path, \"r\", \"utf-8\") as f: robots_txt_contents = f.read() soup = BeautifulSoup(robots_txt_contents, \"lxml\") robots_table = soup.find_all(\"table\")[0] with open(f\"{self.output_folder}/robots.txt\", \"w\") as f: for row in robots_table.tbody.find_all(\"tr\"): f.write(\"\".join([cell.text.strip(\"\\r\") for cell in row(\"td\")])) f.write(\"\\n\") shutil.rmtree(Path(self.output_folder, self.config[\"pages\"][\"robots\"])) else: with open(f\"{self.output_folder}/robots.txt\", \"w\") as f: f.write(\"User-agent: * \\n\") f.write(\"Disallow: /wp-admin/ \\n\") f.write(\"Allow: /wp-admin/admin-ajax.php \\n\") helpers.log_to_console(\"INFO\", \"Created robots.txt file\") download_zip_file() \u00b6 Download zip file from remote server Source code in src/main.py def download_zip_file(self): \"\"\"Download zip file from remote server\"\"\" helpers.log_to_console(\"INFO\", configurations[\"zip_url\"]) headers = CaseInsensitiveDict() headers[\"Cache-Control\"] = \"no-cache, no-store, must-revalidate\" headers[\"Pragma\"] = \"no-cache\" headers[\"Expires\"] = \"0\" current_session = requests.session() response = current_session.get(configurations[\"zip_url\"], headers=headers) if response.status_code == 200: with open(self.config[\"zip_file_name\"], \"wb\") as fd: for chunk in response.iter_content(chunk_size=128): fd.write(chunk) helpers.log_to_console(\"INFO\", \"Simply Static Zip File Downloaded\") else: helpers.log_to_console(\"ERROR\", \"Simply Static Zip File Not available\") current_session.cookies.clear() extract_zip_file() \u00b6 Extract simply static zip file to ouput folder. Source code in src/main.py def extract_zip_file(self): \"\"\"Extract simply static zip file to ouput folder.\"\"\" if self.output_folder.is_dir(): zf = ZipFile(self.zip_file_path, \"r\") zf.extractall(self.output_folder) zf.close() helpers.log_to_console(\"INFO\", \"Zip File Extracted\") else: helpers.log_to_console(\"ERROR\", \"Cannot extract Zip File\") fix_404_error_page() \u00b6 Fix 404 page by moving it to home directory. It deletes old folder. Source code in src/main.py def fix_404_error_page(self): \"\"\"Fix 404 page by moving it to home directory. It deletes old folder.\"\"\" try: with codecs.open(self._404_page, \"r\", \"utf-8\") as f: contents_404_page = f.read() contents_404_page = helpers.update_links( contents_404_page, self.config[\"callback_home\"], self.config[\"callback_deploy_url\"], ) with open( Path(self.output_folder, \"404.html\"), \"w\", encoding=\"utf-8\" ) as f: f.write(contents_404_page) helpers.log_to_console(\"INFO\", \"404 Page Created\") shutil.rmtree(Path(self.output_folder, self.config[\"pages\"][\"404\"])) helpers.log_to_console(\"INFO\", \"404 Folder Removed\") except: helpers.log_to_console(\"ERROR\", \"404 Page Not Created\") fix_home_page() \u00b6 Fix Schemas and other links on home page which are ignored by simply static plugin. Source code in src/main.py def fix_home_page(self): \"\"\"Fix Schemas and other links on home page which are ignored by simply static plugin.\"\"\" home_page_path = Path(self.output_folder, \"index.html\") try: with codecs.open(home_page_path, \"r\", \"utf-8\") as f: contents_home_page = f.read() contents_home_page = helpers.update_links( contents_home_page, self.config[\"callback_home\"], self.config[\"callback_deploy_url\"], ) with open(home_page_path, \"w\", encoding=\"utf-8\") as f: f.write(contents_home_page) helpers.log_to_console(\"INFO\", \"Fixed Home Page\") except: helpers.log_to_console(\"ERROR\", \"Home Page can not be fixed\")","title":"simply-static-netlify object"},{"location":"simply-static-netlify/#staticwordpressnetlify-class","text":"This is a class processing Simply Static WordPress Plugin and converting it to netlify static site. Attributes: Name Type Description config dic Contains all important configurations about the class. output_folder Path Contains Path for output folder location in Netlify zip_file_path Path ZIP File Path to download simply-static-zip file freom remote server. redirect_page Path Contains Path of redirect page robots_txt_page Path Contains Path of robots.txt page self._404_page Path Contains Path of 404 Page Source code in src/main.py class StaticWordPressNetlify: \"\"\" This is a class processing Simply Static WordPress Plugin and converting it to netlify static site. Attributes: config (dic): Contains all important configurations about the class. output_folder (Path): Contains Path for output folder location in Netlify zip_file_path (Path): ZIP File Path to download simply-static-zip file freom remote server. redirect_page (Path): Contains Path of redirect page robots_txt_page (Path): Contains Path of robots.txt page self._404_page (Path): Contains Path of 404 Page \"\"\" def __init__(self, config_=None): \"\"\"Initialize StaticWordPressNetlify objet with a config values. Args: config_ (dict, optional): contains diverse conditions for StaticWordPressNetlify object. \"\"\" if config_: self.config = config_ self.output_folder = Path(self.config[\"root\"], self.config[\"output_folder\"]) self.zip_file_path = Path(self.config[\"root\"], self.config[\"zip_file_name\"]) self.redirect_page = Path( self.output_folder, self.config[\"pages\"][\"redirect\"] ) self.robots_txt_page = Path( self.output_folder, self.config[\"pages\"][\"robots\"] ) self._404_page = Path( self.output_folder, self.config[\"pages\"][\"404\"], \"index.html\" ) def download_zip_file(self): \"\"\"Download zip file from remote server\"\"\" helpers.log_to_console(\"INFO\", configurations[\"zip_url\"]) headers = CaseInsensitiveDict() headers[\"Cache-Control\"] = \"no-cache, no-store, must-revalidate\" headers[\"Pragma\"] = \"no-cache\" headers[\"Expires\"] = \"0\" current_session = requests.session() response = current_session.get(configurations[\"zip_url\"], headers=headers) if response.status_code == 200: with open(self.config[\"zip_file_name\"], \"wb\") as fd: for chunk in response.iter_content(chunk_size=128): fd.write(chunk) helpers.log_to_console(\"INFO\", \"Simply Static Zip File Downloaded\") else: helpers.log_to_console(\"ERROR\", \"Simply Static Zip File Not available\") current_session.cookies.clear() def create_output_folder(self): \"\"\"Create Ouput Folder it it doesnot exist.\"\"\" if not self.output_folder.is_dir(): self.output_folder.mkdir(parents=True, exist_ok=True) helpers.log_to_console(\"INFO\", \"Output Folder Created\") else: helpers.log_to_console(\"ERROR\", \"Cannot Create Output Folder\") def create_robots_txt(self): \"\"\"Create Robots.txt File using robots-txt page. Default would be ``User-agent: *``\"\"\" robots_path = Path( self.robots_txt_page, \"index.html\", ) if robots_path.exists(): with codecs.open(robots_path, \"r\", \"utf-8\") as f: robots_txt_contents = f.read() soup = BeautifulSoup(robots_txt_contents, \"lxml\") robots_table = soup.find_all(\"table\")[0] with open(f\"{self.output_folder}/robots.txt\", \"w\") as f: for row in robots_table.tbody.find_all(\"tr\"): f.write(\"\".join([cell.text.strip(\"\\r\") for cell in row(\"td\")])) f.write(\"\\n\") shutil.rmtree(Path(self.output_folder, self.config[\"pages\"][\"robots\"])) else: with open(f\"{self.output_folder}/robots.txt\", \"w\") as f: f.write(\"User-agent: * \\n\") f.write(\"Disallow: /wp-admin/ \\n\") f.write(\"Allow: /wp-admin/admin-ajax.php \\n\") helpers.log_to_console(\"INFO\", \"Created robots.txt file\") def extract_zip_file(self): \"\"\"Extract simply static zip file to ouput folder.\"\"\" if self.output_folder.is_dir(): zf = ZipFile(self.zip_file_path, \"r\") zf.extractall(self.output_folder) zf.close() helpers.log_to_console(\"INFO\", \"Zip File Extracted\") else: helpers.log_to_console(\"ERROR\", \"Cannot extract Zip File\") def fix_404_error_page(self): \"\"\"Fix 404 page by moving it to home directory. It deletes old folder.\"\"\" try: with codecs.open(self._404_page, \"r\", \"utf-8\") as f: contents_404_page = f.read() contents_404_page = helpers.update_links( contents_404_page, self.config[\"callback_home\"], self.config[\"callback_deploy_url\"], ) with open( Path(self.output_folder, \"404.html\"), \"w\", encoding=\"utf-8\" ) as f: f.write(contents_404_page) helpers.log_to_console(\"INFO\", \"404 Page Created\") shutil.rmtree(Path(self.output_folder, self.config[\"pages\"][\"404\"])) helpers.log_to_console(\"INFO\", \"404 Folder Removed\") except: helpers.log_to_console(\"ERROR\", \"404 Page Not Created\") def fix_home_page(self): \"\"\"Fix Schemas and other links on home page which are ignored by simply static plugin.\"\"\" home_page_path = Path(self.output_folder, \"index.html\") try: with codecs.open(home_page_path, \"r\", \"utf-8\") as f: contents_home_page = f.read() contents_home_page = helpers.update_links( contents_home_page, self.config[\"callback_home\"], self.config[\"callback_deploy_url\"], ) with open(home_page_path, \"w\", encoding=\"utf-8\") as f: f.write(contents_home_page) helpers.log_to_console(\"INFO\", \"Fixed Home Page\") except: helpers.log_to_console(\"ERROR\", \"Home Page can not be fixed\") def build_search_index(self): \"\"\"Buidl search index by using title, body content and href of a given page\"\"\" helpers.log_to_console(\"INFO\", \"Start Building Search Index\") try: # Copy Search.js into search folder source_path = Path(self.config[\"root\"], \"src/search.js\") target_path = Path( self.output_folder, f\"{self.config['pages']['search']}/search.js\" ) shutil.copyfile(source_path, target_path) # Now Process all foldre with content/index.html files paths_to_pages = [ path.split(\"index.html\")[0] for path in glob.glob(f\"{self.output_folder}/**\", recursive=True) if path.endswith(\"index.html\") ] search_index_output = [] for page_path in paths_to_pages: make_title = self.config[\"search\"][\"title\"] make_url = self.config[\"search\"][\"url\"] make_text = self.config[\"search\"][\"text\"] make_images = self.config[\"search\"][\"images\"] document_path = Path(page_path, \"index.html\") if document_path.exists(): with codecs.open(document_path, \"r\", \"utf-8\") as f: contents_document_page = f.read() contents_document_page = helpers.update_links( contents_document_page, self.config[\"callback_home\"], self.config[\"callback_deploy_url\"], ) soup = BeautifulSoup(contents_document_page, \"lxml\") # append tags only if search page is specified if \"/search/\" in str(document_path): script_text = [ soup.new_tag( \"script\", src=LUNR[\"src\"], integrity=LUNR[\"integrity\"], crossorigin=LUNR[\"crossorigin\"], referrerpolicy=LUNR[\"referrerpolicy\"], ), soup.new_tag( \"script\", src=SEARCH_INDEX[\"src\"], ), ] for script in script_text: soup.find(\"head\").append(str(script)) # TODO: In future add support for minification check updated_content = soup.prettify( formatter=HTMLFormatter(helpers.string_formatter) ) with open(document_path, \"w\", encoding=\"utf-8\") as f: f.write(updated_content) title = soup.find(\"title\") title = title.string if title else None url = soup.find(\"meta\", {\"property\": \"og:url\"}) url = url[\"content\"] if url else None canonical = soup.find(\"link\", {\"rel\": \"canonical\"}) if canonical: url = canonical[\"href\"] all_strings = soup.body.find_all([\"h1\", \"h2\", \"h3\", \"p\"]) output = [ strings for bd in all_strings for strings in bd.strings ] text = \" \".join(output) if url and document_path.parts[-2] not in [ self.config[\"pages\"][page] for page in self.config[\"pages\"] ]: out = { \"title\": title if make_title else \"\", \"content\": text if make_text else \"\", \"href\": url if make_url else \"\", } search_index_output.append(out) helpers.log_to_console(\"INFO\", url) search_index_json_file_path = Path( self.output_folder, self.config[\"pages\"][\"search\"], \"lunr.json\", ) with open(search_index_json_file_path, \"w\") as fl: json.dump(search_index_output, fl, indent=4) helpers.log_to_console( \"INFO\", \"Prepare Search Index for title, Url and Text\" ) except: helpers.log_to_console(\"ERROR\", \"Search Index not Generated\") def clean_directory_check(self): \"\"\" \"\"\" helpers.log_to_console( \"INFO\", \"Started Removing Bad URLs/Directories for forceful deploy.\" ) files = [f for f in glob.glob(f\"{self.output_folder}/**/*\", recursive=True)] for f in files: if \"#\" in f or \"?\" in f: if os.path.exists(f) and os.path.isdir(f): print(f\"removing {f} for forceful deploy.\") shutil.rmtree(f) helpers.log_to_console(\"INFO\", \"Removed Bad URLs/Directories from deployement.\") def create_redirect_toml_file(self): \"\"\"Create netlify.toml file with redirects information freom redirect page.\"\"\" helpers.log_to_console( \"INFO\", \"Source Redirect Page \" + self.config[\"pages\"][\"redirect\"] ) redirect_path = Path( self.redirect_page, \"index.html\", ) rules = [ [ \"[[redirects]]\\n\", 'from = \"/*\"\\n', f'to = \"/{self.config[\"pages\"][\"search\"]}\"\\n', \"status = 301\\n\", 'query = {s = \":s\"}\\n', \"force = true\\n\", \"\\n\", ] ] if redirect_path.exists(): with codecs.open(redirect_path, \"r\", \"utf-8\") as f: contents = f.read() soup = BeautifulSoup(contents, \"lxml\") redirect_table = soup.find_all(\"table\")[0] table_data = [ [cell.text.strip(\"\\r\") for cell in row(\"td\")] for row in redirect_table.tbody.find_all(\"tr\") ] helpers.log_to_console( \"WARNING\", f\"Redirect Rules found - {len(table_data)}\" ) if len(table_data) > 1: for data in table_data[1:]: if data[3].strip() == \"1\": rules.append( [ f\"[[redirects]]\\n\", f'{table_data[0][0].lower().strip()} = \"{data[0].strip()}\"\\n', f'{table_data[0][1].lower().strip()} = \"{data[1].strip()}\"\\n', f\"{table_data[0][2].lower().strip()} = {data[2].strip()}\\n\", \"\\n\", ] ) shutil.rmtree(self.redirect_page) else: helpers.log_to_console(\"WARNING\", \"No Redirect File found\") netlify_toml_file = Path(self.output_folder, \"netlify.toml\") with open(netlify_toml_file, \"w\", encoding=\"utf-8\") as f: f.writelines([\"\".join(rule) for rule in rules]) helpers.log_to_console(\"INFO\", \"Netlify toml File Created Successfully\")","title":"StaticWordPressNetlify Class"},{"location":"simply-static-netlify/#src.main.StaticWordPressNetlify.__init__","text":"Initialize StaticWordPressNetlify objet with a config values. Parameters: Name Type Description Default config_ dict contains diverse conditions for StaticWordPressNetlify object. None Source code in src/main.py def __init__(self, config_=None): \"\"\"Initialize StaticWordPressNetlify objet with a config values. Args: config_ (dict, optional): contains diverse conditions for StaticWordPressNetlify object. \"\"\" if config_: self.config = config_ self.output_folder = Path(self.config[\"root\"], self.config[\"output_folder\"]) self.zip_file_path = Path(self.config[\"root\"], self.config[\"zip_file_name\"]) self.redirect_page = Path( self.output_folder, self.config[\"pages\"][\"redirect\"] ) self.robots_txt_page = Path( self.output_folder, self.config[\"pages\"][\"robots\"] ) self._404_page = Path( self.output_folder, self.config[\"pages\"][\"404\"], \"index.html\" )","title":"__init__()"},{"location":"simply-static-netlify/#src.main.StaticWordPressNetlify.build_search_index","text":"Buidl search index by using title, body content and href of a given page Source code in src/main.py def build_search_index(self): \"\"\"Buidl search index by using title, body content and href of a given page\"\"\" helpers.log_to_console(\"INFO\", \"Start Building Search Index\") try: # Copy Search.js into search folder source_path = Path(self.config[\"root\"], \"src/search.js\") target_path = Path( self.output_folder, f\"{self.config['pages']['search']}/search.js\" ) shutil.copyfile(source_path, target_path) # Now Process all foldre with content/index.html files paths_to_pages = [ path.split(\"index.html\")[0] for path in glob.glob(f\"{self.output_folder}/**\", recursive=True) if path.endswith(\"index.html\") ] search_index_output = [] for page_path in paths_to_pages: make_title = self.config[\"search\"][\"title\"] make_url = self.config[\"search\"][\"url\"] make_text = self.config[\"search\"][\"text\"] make_images = self.config[\"search\"][\"images\"] document_path = Path(page_path, \"index.html\") if document_path.exists(): with codecs.open(document_path, \"r\", \"utf-8\") as f: contents_document_page = f.read() contents_document_page = helpers.update_links( contents_document_page, self.config[\"callback_home\"], self.config[\"callback_deploy_url\"], ) soup = BeautifulSoup(contents_document_page, \"lxml\") # append tags only if search page is specified if \"/search/\" in str(document_path): script_text = [ soup.new_tag( \"script\", src=LUNR[\"src\"], integrity=LUNR[\"integrity\"], crossorigin=LUNR[\"crossorigin\"], referrerpolicy=LUNR[\"referrerpolicy\"], ), soup.new_tag( \"script\", src=SEARCH_INDEX[\"src\"], ), ] for script in script_text: soup.find(\"head\").append(str(script)) # TODO: In future add support for minification check updated_content = soup.prettify( formatter=HTMLFormatter(helpers.string_formatter) ) with open(document_path, \"w\", encoding=\"utf-8\") as f: f.write(updated_content) title = soup.find(\"title\") title = title.string if title else None url = soup.find(\"meta\", {\"property\": \"og:url\"}) url = url[\"content\"] if url else None canonical = soup.find(\"link\", {\"rel\": \"canonical\"}) if canonical: url = canonical[\"href\"] all_strings = soup.body.find_all([\"h1\", \"h2\", \"h3\", \"p\"]) output = [ strings for bd in all_strings for strings in bd.strings ] text = \" \".join(output) if url and document_path.parts[-2] not in [ self.config[\"pages\"][page] for page in self.config[\"pages\"] ]: out = { \"title\": title if make_title else \"\", \"content\": text if make_text else \"\", \"href\": url if make_url else \"\", } search_index_output.append(out) helpers.log_to_console(\"INFO\", url) search_index_json_file_path = Path( self.output_folder, self.config[\"pages\"][\"search\"], \"lunr.json\", ) with open(search_index_json_file_path, \"w\") as fl: json.dump(search_index_output, fl, indent=4) helpers.log_to_console( \"INFO\", \"Prepare Search Index for title, Url and Text\" ) except: helpers.log_to_console(\"ERROR\", \"Search Index not Generated\")","title":"build_search_index()"},{"location":"simply-static-netlify/#src.main.StaticWordPressNetlify.create_output_folder","text":"Create Ouput Folder it it doesnot exist. Source code in src/main.py def create_output_folder(self): \"\"\"Create Ouput Folder it it doesnot exist.\"\"\" if not self.output_folder.is_dir(): self.output_folder.mkdir(parents=True, exist_ok=True) helpers.log_to_console(\"INFO\", \"Output Folder Created\") else: helpers.log_to_console(\"ERROR\", \"Cannot Create Output Folder\")","title":"create_output_folder()"},{"location":"simply-static-netlify/#src.main.StaticWordPressNetlify.create_redirect_toml_file","text":"Create netlify.toml file with redirects information freom redirect page. Source code in src/main.py def create_redirect_toml_file(self): \"\"\"Create netlify.toml file with redirects information freom redirect page.\"\"\" helpers.log_to_console( \"INFO\", \"Source Redirect Page \" + self.config[\"pages\"][\"redirect\"] ) redirect_path = Path( self.redirect_page, \"index.html\", ) rules = [ [ \"[[redirects]]\\n\", 'from = \"/*\"\\n', f'to = \"/{self.config[\"pages\"][\"search\"]}\"\\n', \"status = 301\\n\", 'query = {s = \":s\"}\\n', \"force = true\\n\", \"\\n\", ] ] if redirect_path.exists(): with codecs.open(redirect_path, \"r\", \"utf-8\") as f: contents = f.read() soup = BeautifulSoup(contents, \"lxml\") redirect_table = soup.find_all(\"table\")[0] table_data = [ [cell.text.strip(\"\\r\") for cell in row(\"td\")] for row in redirect_table.tbody.find_all(\"tr\") ] helpers.log_to_console( \"WARNING\", f\"Redirect Rules found - {len(table_data)}\" ) if len(table_data) > 1: for data in table_data[1:]: if data[3].strip() == \"1\": rules.append( [ f\"[[redirects]]\\n\", f'{table_data[0][0].lower().strip()} = \"{data[0].strip()}\"\\n', f'{table_data[0][1].lower().strip()} = \"{data[1].strip()}\"\\n', f\"{table_data[0][2].lower().strip()} = {data[2].strip()}\\n\", \"\\n\", ] ) shutil.rmtree(self.redirect_page) else: helpers.log_to_console(\"WARNING\", \"No Redirect File found\") netlify_toml_file = Path(self.output_folder, \"netlify.toml\") with open(netlify_toml_file, \"w\", encoding=\"utf-8\") as f: f.writelines([\"\".join(rule) for rule in rules]) helpers.log_to_console(\"INFO\", \"Netlify toml File Created Successfully\")","title":"create_redirect_toml_file()"},{"location":"simply-static-netlify/#src.main.StaticWordPressNetlify.create_robots_txt","text":"Create Robots.txt File using robots-txt page. Default would be User-agent: * Source code in src/main.py def create_robots_txt(self): \"\"\"Create Robots.txt File using robots-txt page. Default would be ``User-agent: *``\"\"\" robots_path = Path( self.robots_txt_page, \"index.html\", ) if robots_path.exists(): with codecs.open(robots_path, \"r\", \"utf-8\") as f: robots_txt_contents = f.read() soup = BeautifulSoup(robots_txt_contents, \"lxml\") robots_table = soup.find_all(\"table\")[0] with open(f\"{self.output_folder}/robots.txt\", \"w\") as f: for row in robots_table.tbody.find_all(\"tr\"): f.write(\"\".join([cell.text.strip(\"\\r\") for cell in row(\"td\")])) f.write(\"\\n\") shutil.rmtree(Path(self.output_folder, self.config[\"pages\"][\"robots\"])) else: with open(f\"{self.output_folder}/robots.txt\", \"w\") as f: f.write(\"User-agent: * \\n\") f.write(\"Disallow: /wp-admin/ \\n\") f.write(\"Allow: /wp-admin/admin-ajax.php \\n\") helpers.log_to_console(\"INFO\", \"Created robots.txt file\")","title":"create_robots_txt()"},{"location":"simply-static-netlify/#src.main.StaticWordPressNetlify.download_zip_file","text":"Download zip file from remote server Source code in src/main.py def download_zip_file(self): \"\"\"Download zip file from remote server\"\"\" helpers.log_to_console(\"INFO\", configurations[\"zip_url\"]) headers = CaseInsensitiveDict() headers[\"Cache-Control\"] = \"no-cache, no-store, must-revalidate\" headers[\"Pragma\"] = \"no-cache\" headers[\"Expires\"] = \"0\" current_session = requests.session() response = current_session.get(configurations[\"zip_url\"], headers=headers) if response.status_code == 200: with open(self.config[\"zip_file_name\"], \"wb\") as fd: for chunk in response.iter_content(chunk_size=128): fd.write(chunk) helpers.log_to_console(\"INFO\", \"Simply Static Zip File Downloaded\") else: helpers.log_to_console(\"ERROR\", \"Simply Static Zip File Not available\") current_session.cookies.clear()","title":"download_zip_file()"},{"location":"simply-static-netlify/#src.main.StaticWordPressNetlify.extract_zip_file","text":"Extract simply static zip file to ouput folder. Source code in src/main.py def extract_zip_file(self): \"\"\"Extract simply static zip file to ouput folder.\"\"\" if self.output_folder.is_dir(): zf = ZipFile(self.zip_file_path, \"r\") zf.extractall(self.output_folder) zf.close() helpers.log_to_console(\"INFO\", \"Zip File Extracted\") else: helpers.log_to_console(\"ERROR\", \"Cannot extract Zip File\")","title":"extract_zip_file()"},{"location":"simply-static-netlify/#src.main.StaticWordPressNetlify.fix_404_error_page","text":"Fix 404 page by moving it to home directory. It deletes old folder. Source code in src/main.py def fix_404_error_page(self): \"\"\"Fix 404 page by moving it to home directory. It deletes old folder.\"\"\" try: with codecs.open(self._404_page, \"r\", \"utf-8\") as f: contents_404_page = f.read() contents_404_page = helpers.update_links( contents_404_page, self.config[\"callback_home\"], self.config[\"callback_deploy_url\"], ) with open( Path(self.output_folder, \"404.html\"), \"w\", encoding=\"utf-8\" ) as f: f.write(contents_404_page) helpers.log_to_console(\"INFO\", \"404 Page Created\") shutil.rmtree(Path(self.output_folder, self.config[\"pages\"][\"404\"])) helpers.log_to_console(\"INFO\", \"404 Folder Removed\") except: helpers.log_to_console(\"ERROR\", \"404 Page Not Created\")","title":"fix_404_error_page()"},{"location":"simply-static-netlify/#src.main.StaticWordPressNetlify.fix_home_page","text":"Fix Schemas and other links on home page which are ignored by simply static plugin. Source code in src/main.py def fix_home_page(self): \"\"\"Fix Schemas and other links on home page which are ignored by simply static plugin.\"\"\" home_page_path = Path(self.output_folder, \"index.html\") try: with codecs.open(home_page_path, \"r\", \"utf-8\") as f: contents_home_page = f.read() contents_home_page = helpers.update_links( contents_home_page, self.config[\"callback_home\"], self.config[\"callback_deploy_url\"], ) with open(home_page_path, \"w\", encoding=\"utf-8\") as f: f.write(contents_home_page) helpers.log_to_console(\"INFO\", \"Fixed Home Page\") except: helpers.log_to_console(\"ERROR\", \"Home Page can not be fixed\")","title":"fix_home_page()"},{"location":"tutorial/","text":"Tutorial: How to Deploy Simply Static Post Process \u00b6 Please read/watch detailed tutorial on Seowings Tutorial Page .","title":"Tutorial"},{"location":"tutorial/#tutorial-how-to-deploy-simply-static-post-process","text":"Please read/watch detailed tutorial on Seowings Tutorial Page .","title":"Tutorial: How to Deploy Simply Static Post Process"}]}